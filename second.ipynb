{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b85807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5219f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomAffine(degrees=(0,135), translate=(0.1, 0.3), scale=(0.8, 0.95)),\n",
    "    transforms.RandomInvert(p=0.5),\n",
    "    transforms.RandomAdjustSharpness(sharpness_factor=2,p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=2, saturation=1.5, hue=0.5),\n",
    "    transforms.functional.equalize,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5, 0.5],[0.5,0.5,0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edb6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cdDataset(Dataset):\n",
    "    def __init__(self, path, tfm=test_tfm, files=None, mode=None):\n",
    "        super(cdDataset, self).__init__()\n",
    "        self.path = path\n",
    "        if mode == 'test':\n",
    "            def sort_(file_path):\n",
    "                return int(re.search(r'\\d+', os.path.basename(file_path)).group())\n",
    "            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")], key=sort_)\n",
    "        else:\n",
    "            self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        self.transform = tfm\n",
    "        self.mode = mode\n",
    "        if mode != 'test':\n",
    "            train_files, valid_files = train_test_split(self.files, test_size=0.2)\n",
    "            if mode == 'train':\n",
    "                self.files = train_files\n",
    "            elif mode == 'val':\n",
    "                self.files = valid_files\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        if self.mode != 'test':\n",
    "            label_str = fname.split('\\\\')[-1].split(\".\")[0]\n",
    "            label = 0 if label_str == 'cat' else 1\n",
    "        else:\n",
    "            label = -1\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c174734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1(in_planes, places, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_planes, out_channels=places, kernel_size=7, stride=stride, padding=3, bias=False),\n",
    "        nn.BatchNorm2d(places),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "    )\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_places, places, stride=1, downsampling=False, expansion=4):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_places, out_channels=places, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(places),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=places, out_channels=places * self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(places * self.expansion),\n",
    "        )\n",
    "\n",
    "        if self.downsampling:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_places, out_channels=places * self.expansion, kernel_size=1, stride=stride,\n",
    "                          bias=False),\n",
    "                nn.BatchNorm2d(places * self.expansion)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bottleneck(x)\n",
    "\n",
    "        if self.downsampling:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, blocks, num_classes=1, expansion=4):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.expansion = expansion\n",
    "\n",
    "        self.conv1 = Conv1(in_planes=3, places=64)\n",
    "\n",
    "        self.layer1 = self.make_layer(in_places=64, places=64, block=blocks[0], stride=1)\n",
    "        self.layer2 = self.make_layer(in_places=256, places=128, block=blocks[1], stride=2)\n",
    "        self.layer3 = self.make_layer(in_places=512, places=256, block=blocks[2], stride=2)\n",
    "        self.layer4 = self.make_layer(in_places=1024, places=512, block=blocks[3], stride=2)\n",
    "\n",
    "        self.MaxPool2d = nn.MaxPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def make_layer(self, in_places, places, block, stride):\n",
    "        layers = []\n",
    "        layers.append(Bottleneck(in_places, places, stride, downsampling=True))\n",
    "        for i in range(1, block):\n",
    "            layers.append(Bottleneck(places * self.expansion, places))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.MaxPool2d(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x.view(x.size(0), -1)).squeeze(1)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "def ResNet50():\n",
    "    return ResNet([3, 4, 6, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5144add",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "_dataset_dir = r\"D:\\sast\" \n",
    "device = \"cuda\" \n",
    "n_epochs = 40\n",
    "patience = 300\n",
    "train_set = cdDataset(os.path.join(_dataset_dir,\"train\"), tfm=train_tfm,mode='train')\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True) \n",
    "valid_set = cdDataset(os.path.join(_dataset_dir,\"test\"),tfm=test_tfm,mode='val') \n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046e62a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722a416cb593493a81027679f0c28500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m imgs, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(imgs\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m---> 19\u001b[0m label\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, label)\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ResNet50().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "best_loss = 0\n",
    "best_acc =0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        logits = model(imgs.to(device))\n",
    "        label=labels.to(device).float()\n",
    "        loss = criterion(logits, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=8)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        correct_train +=  ((logits - labels.to(device)).abs() < 0.2).cpu().sum().item()\n",
    "\n",
    "        accuracy_train = correct_train\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = accuracy_train / total_train\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f} accuracy = {train_acc:.3f}\")\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    correct_valid = 0\n",
    "    total_valid = 0\n",
    "    for batch in tqdm(valid_loader):\n",
    "        imgs, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "        label=labels.to(device).float()\n",
    "        loss = criterion(logits, label)\n",
    "        \n",
    "\n",
    "        valid_loss.append(loss.item())\n",
    "        correct_valid +=  ((logits - labels.to(device)).abs() < 0.2).cpu().sum().item()\n",
    "        \n",
    "        total_valid += labels.size(0)\n",
    "        accuracy_val = correct_valid\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc =accuracy_val / total_valid\n",
    "\n",
    "\n",
    "    if valid_acc > best_acc:\n",
    "        with open(f\".sample_log.txt\", \"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    else:\n",
    "        with open(f\"./sample_log.txt\", \"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "    if valid_acc > best_acc:\n",
    "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "        checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, 'sample_best.ckpt')\n",
    "        torch.save(checkpoint, f\"sample_best.ckpt\")  \n",
    "        best_acc = valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cab8e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set = cdDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm,mode='test')\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "model_best = ResNet50().to(device)\n",
    "checkpoint = torch.load(f\"sample_best.ckpt\")\n",
    "model_best.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        prediction += test_pred.cpu().squeeze().tolist()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"ID\"] = [i for i in range(1,len(test_set)+1)]\n",
    "df['TARGET'] = pd.Series(prediction).round(2)\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65178e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
